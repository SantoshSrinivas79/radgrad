# Spring 2017 Usability Test Results

## Subject A (March 13, 2017)

Subject A is a Senior in ICS who plans to graduate this year. Subject A had a significant amount of extra-curricular activities and coursework; A's initial ICE score was 80/132/115 (Level 4).
 
Here are some observations from review of the screencast:
 
1. On the ICE Points page, the "100" in the circles was confusing (since the subject's ICE score was over 100 in two categories). Recommend showing only the actual ICE value in the circle. The explanatory boxes provide enough breakdown.

2. Opportunities scroll off top of screen (already addressed by Aljon).

3. "Recommended opportunities is really useful. It's hard to know what's out there unless you watch the emails from Gerald."

4. Rating widget for reviews should display all five star options without scrolling.

5. "You're the kind of student who didn't need RadGrad."  "Yes, but I had to put in a lot of extra work to get there. This makes it much simpler to see what you have to do."

6. What are three good things about RadGrad?  

    * Degree Planner: it makes it easier to see where you want to go.  

    * Recommended opportunities is really useful.  

    * I don't think it's expressed enough to students to do more than just take classes.  
    
    * I like the idea of gamifying the process. The stickers can be a signifier of who you might want to talk to.
     
7. What are three things that could be improved?

    * Figuring out where to find things seems difficult, but maybe after a training with Gerald it would be OK.
    
    * Performance is an issue.
    
    
### Subject C (March 30, 2017)

Subject C has just recently graduated from the ICS program.  Subject C's ICE score was 10/134/10, which achieved Level 3. Because Subject C had already graduated, there were no planned courses or opportunities. 

Unfortunately, no screencast was made of the session (on Philip's laptop, you must start screenflow prior to engaging Apple TV or else really, really, really bad things happen. And those bad things happened during this beta test.)

However, Amy and Philip took notes during the session and discussed the test afterwards. Here are our findings. 

1. Performance appears to have been eliminated as a usability issue. There was no discussion of loading time delays or any other performance issues during this beta test.

2. We discovered several opportunities for improvement to the usability of the system, summarized in [Issue 100](https://github.com/radgrad/radgrad/issues/100).

3. The Recommended Courses and Recommended Opportunities widgets on the home page have unintuitive scrolling behavior. First, it is not obvious that they scroll. Second, it is not obvious how to make them scroll. One idea: when you hover the mouse over the pane, right and left arrows appear to show you that you can scroll horizontally left and right.

5. Good things:

  * RadGrad provides details about courses and opportunities not known to this student when they were in the department. Subject C learned about clubs and opportunities for the first time while perusing the interface. The subject was visibly excited to learn about opportunities and courses.
  
  * Subject C liked the recommendations and said that their experience was almost like a "random walk" through the curriculum.
  
  * Subject C found out during interviews that having an internship would have been helpful.  Felt that RadGrad would be useful to students in helping them understand the benefits of extracurricular activities.
  
6. What could be improved?

   * Subject C brought up the issue of stalking, and suggested it would be good to be able to opt-out of revealing your current/planned courses and opportunities in order to reduce the ability of stalkers to know your whereabouts.  

